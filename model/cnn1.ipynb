{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = str(1)\n",
    "#os.environ[\"TORCH_USE_CUDA_DSA\"]= str(0)\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "from torchsummary import summary\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_train = torch.randn([14231, 1, 9000, 18])\\nY_train = torch.ones([14231, 1])\\nX_val = torch.randn([1581, 1, 9000, 18])\\nY_val = torch.ones([1581, 1])\\nX_test = torch.randn([10249, 1, 9000, 18])\\nY_test = torch.ones([10249, 1])\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "X_train = torch.randn([14231, 1, 9000, 18])\n",
    "Y_train = torch.ones([14231, 1])\n",
    "X_val = torch.randn([1581, 1, 9000, 18])\n",
    "Y_val = torch.ones([1581, 1])\n",
    "X_test = torch.randn([10249, 1, 9000, 18])\n",
    "Y_test = torch.ones([10249, 1])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 16, 9000, 1]             304\n",
      "       BatchNorm2d-2          [-1, 16, 9000, 1]              32\n",
      "         ZeroPad2d-3         [-1, 16, 9020, 21]               0\n",
      "            Conv2d-4         [-1, 320, 1804, 4]         128,320\n",
      "       BatchNorm2d-5         [-1, 320, 1804, 4]             640\n",
      "            Linear-6                    [-1, 1]       2,309,121\n",
      "================================================================\n",
      "Total params: 2,438,417\n",
      "Trainable params: 2,438,417\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.62\n",
      "Forward/backward pass size (MB): 60.55\n",
      "Params size (MB): 9.30\n",
      "Estimated Total Size (MB): 70.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.T = 9000\n",
    "\n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 18))\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16, False)\n",
    "        self.padding1 = nn.ZeroPad2d(10)\n",
    "\n",
    "        # Layer 2\n",
    "        self.conv2 = nn.Conv2d(16, 320, (5, 5), stride=5)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(320, False)\n",
    "\n",
    "        # FC\n",
    "        self.fc1 = nn.Linear(2309120, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.padding1(x)\n",
    "        # Layer 2\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "\n",
    "\n",
    "        #x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "\n",
    "\n",
    "        x = x.reshape(-1, x.shape[1]* x.shape[2]* x.shape[3])\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = CNN().cuda()\n",
    "    summary(model.cuda(), (1, 9000, 18))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
