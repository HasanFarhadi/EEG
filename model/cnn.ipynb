{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from datagen.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from datagen import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seglength = 9000\n",
    "train_ratio = 0.8\n",
    "pnes_train, pnes_test, pnes_train_labels, pnes_test_labels = Data('D:\\EEG\\PNES', train_ratio, seglength, class_num = 3)\n",
    "temporal_train, temporal_test, temporal_train_labels, temporal_test_labels = Data('D:\\EEG\\TLE', train_ratio, seglength, class_num = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_ratio = 0.1\n",
    "X_train = torch.cat((pnes_train, temporal_train))\n",
    "Y_train = torch.cat((pnes_train_labels, temporal_train_labels))\n",
    "\n",
    "X_test = torch.cat((pnes_test, temporal_test))\n",
    "Y_test = torch.cat((pnes_test_labels, temporal_test_labels))\n",
    "\n",
    "X_val = X_train[:int(val_ratio * len(Y_train))]\n",
    "Y_val = Y_train[:int(val_ratio * len(Y_train))]\n",
    "\n",
    "X_train = X_train[int(val_ratio * len(Y_train)):]\n",
    "Y_train = Y_train[int(val_ratio * len(Y_train)):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6675, 1, 9000, 20])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8650, 0.4775, 0.8916, 0.4809], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.T = 9000\n",
    "\n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 20), padding = 0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16, False)\n",
    "        \n",
    "        # Layer 2\n",
    "        self.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n",
    "        self.conv2 = nn.Conv2d(1, 4, (2, 32))\n",
    "        self.batchnorm2 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 4)\n",
    "        \n",
    "        # Layer 3\n",
    "        self.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n",
    "        self.conv3 = nn.Conv2d(4, 4, (8, 4))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 4))\n",
    "        \n",
    "        # FC Layer\n",
    "        # NOTE: This dimension will depend on the number of timestamps per sample in your data.\n",
    "        # I have 120 timepoints. \n",
    "        self.fc1 = nn.Linear(4496, 4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        \n",
    "        # Layer 2\n",
    "        x = self.padding1(x)\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling2(x)\n",
    "        \n",
    "        # Layer 3\n",
    "        x = self.padding2(x)\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling3(x)\n",
    "        \n",
    "        # FC Layer\n",
    "        x = x.reshape(-1)\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model = CNN()        \n",
    "\n",
    "model.forward(torch.Tensor(np.random.rand(1, 1, 9000, 20)))\n",
    "#summary(model.cuda(), (1, 1, 9000, 20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    print(\"\\nEpoch \", epoch)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i in range(int(len(X_train)/batch_size-1)):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = X_train[s:e]\n",
    "        labels = torch.FloatTensor(Y_train[s:e].T*1.0)\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs.cuda(0)), Variable(labels.cuda(0))\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 20, 119, 19])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4, 100, 120, 20)\n",
    "y = nn.Conv2d(100, 20, 2)(x)\n",
    "np.shape(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
