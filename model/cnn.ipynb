{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = str(1)\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"]= str(0)\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Datagen_2.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from Datagen_2 import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seglength = 120\n",
    "train_ratio = 0.8\n",
    "focal_train, focal_test, focal_train_labels, focal_test_labels = Data('D:\\EEG\\FOCAL', train_ratio, seglength, class_num = 0.25)\n",
    "ige_train, ige_test, ige_train_labels, ige_test_labels = Data('D:\\EEG\\IGE', train_ratio, seglength, class_num = 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_ratio = 0.1\n",
    "X_train = torch.cat((focal_train, ige_train))\n",
    "Y_train = torch.cat((focal_train_labels, ige_train_labels))\n",
    "\n",
    "X_test = torch.cat((focal_train, ige_train))\n",
    "Y_test = torch.cat((focal_train_labels, ige_train_labels))\n",
    "\n",
    "X_val = X_train[:int(val_ratio * len(Y_train))]\n",
    "Y_val = Y_train[:int(val_ratio * len(Y_train))]\n",
    "\n",
    "X_train = X_train[int(val_ratio * len(Y_train)):]\n",
    "Y_train = Y_train[int(val_ratio * len(Y_train)):].view(-1, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del focal_train, focal_test, focal_train_labels, focal_test_labels, ige_train, ige_test, ige_train_labels, ige_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, Y, params = [\"acc\"]):\n",
    "    results = []\n",
    "    \n",
    "    \n",
    "    predicted = []\n",
    "    \"\"\" \n",
    "    batch_size=4096\n",
    "    for i in range(int((len(X)/batch_size))):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = Variable(X[s:e])\n",
    "        pred = model(inputs)\n",
    "        \n",
    "        predicted.append(pred.data.cpu().numpy())\n",
    "    \"\"\"        \n",
    "        \n",
    "    inputs = Variable(X)\n",
    "    predicted = model(inputs)\n",
    "    \n",
    "    predicted = predicted.data.cpu().numpy()\n",
    "    \n",
    "    for param in params:\n",
    "        if param == 'acc':\n",
    "            results.append(accuracy_score(Y, np.round(predicted)))\n",
    "        if param == \"auc\":\n",
    "            results.append(roc_auc_score(Y, predicted))\n",
    "        if param == \"recall\":\n",
    "            results.append(recall_score(Y, np.round(predicted)))\n",
    "        if param == \"precision\":\n",
    "            results.append(precision_score(Y, np.round(predicted)))\n",
    "        if param == \"fmeasure\":\n",
    "            precision = precision_score(Y, np.round(predicted))\n",
    "            recall = recall_score(Y, np.round(predicted))\n",
    "            results.append(2*precision*recall/ (precision+recall))\n",
    "    return results\n",
    "\n",
    "#evaluate(model, X, Y, params = [\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.T = 9000\n",
    "\n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 18))\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16, False)\n",
    "        self.padding1 = nn.ZeroPad2d(10)\n",
    "\n",
    "        # Layer 2\n",
    "        self.conv2 = nn.Conv2d(16, 320, (5, 5), stride=5)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(320, False)\n",
    "\n",
    "        # FC\n",
    "        self.fc1 = nn.Linear(320*28*4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.padding1(x)\n",
    "        # Layer 2\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "\n",
    "\n",
    "        #x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "\n",
    "\n",
    "        x = x.reshape(-1, x.shape[1]* x.shape[2]* x.shape[3])\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model = CNN().cuda()\n",
    "\n",
    "#model.forward(X_train[0:200])\n",
    "#summary(model.cuda(), (1, 120, 20))\n",
    "#model.cpu().forward(X_train[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nXX_train = torch.randn([565143, 1, 120, 18])\\nYY_train = torch.randn([565143, 1])\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "XX_train = torch.randn([565143, 1, 120, 18])\n",
    "YY_train = torch.randn([565143, 1])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(YY_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  0\n",
      "\n",
      "Epoch  1\n",
      "\n",
      "Epoch  2\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4096\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(3):  # loop over the dataset multiple times\n",
    "    print(\"\\nEpoch \", epoch)\n",
    "    running_loss = 0.0\n",
    "    for i in range(int(len(X_train)/batch_size-1)):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = Variable(X_train[s:e].cuda())\n",
    "        labels = Variable(Y_train[s:e].cuda())\n",
    "\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model.forward(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        #print(loss.data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "#print(evaluate(model, X_train.cuda(), Y_train.cuda(), params=[\"fmeasure\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
