{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = str(1)\n",
    "#os.environ[\"TORCH_USE_CUDA_DSA\"]= str(0)\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "from torchsummary import summary\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_train = torch.randn([14231, 1, 9000, 18])\\nY_train = torch.ones([14231, 1])\\nX_val = torch.randn([1581, 1, 9000, 18])\\nY_val = torch.ones([1581, 1])\\nX_test = torch.randn([10249, 1, 9000, 18])\\nY_test = torch.ones([10249, 1])\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "X_train = torch.randn([14231, 1, 9000, 18])\n",
    "Y_train = torch.ones([14231, 1])\n",
    "X_val = torch.randn([1581, 1, 9000, 18])\n",
    "Y_val = torch.ones([1581, 1])\n",
    "X_test = torch.randn([10249, 1, 9000, 18])\n",
    "Y_test = torch.ones([10249, 1])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4077, 0.5923],\n",
      "        [0.4171, 0.5829],\n",
      "        [0.4659, 0.5342],\n",
      "        [0.4353, 0.5647]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class LSTM_CNN_Spatial(nn.Module):\n",
    "    def __init__(self, num_classes, batch_size, T, C, input_size, hidden_size,\n",
    "                 num_layers, spatial_num=8, drop_out=0.5):\n",
    "        super(LSTM_CNN_Spatial, self).__init__()\n",
    "\n",
    "        self.N = batch_size\n",
    "        self.T = T\n",
    "        self.C = C\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.pool = 4\n",
    "        self.seq_len = self.T // self.input_size\n",
    "        self.fc_in = spatial_num * self.hidden_size // self.pool\n",
    "        \n",
    "        self._lstm = nn.LSTM(self.input_size, self.hidden_size, \n",
    "                            self.num_layers, batch_first=True)\n",
    "        self.lstm = nn.ModuleList([self._lstm for i in range(self.C)])\n",
    "        \n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, spatial_num, (self.C, 1)),\n",
    "            nn.BatchNorm2d(spatial_num),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, self.pool)),\n",
    "            nn.Dropout(drop_out)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(self.fc_in , num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # input shape of x: (N, 1, C, T)\n",
    "        self.N = x.shape[0]\n",
    "        x = x.reshape(self.N, self.C, self.seq_len, self.input_size)\n",
    "        _x = None\n",
    "        for index, lstm in enumerate(self.lstm):\n",
    "            lstm_out, _ = lstm(x[:, index, :, :], None)\n",
    "            tmp = lstm_out[:, -1, :]\n",
    "            tmp = tmp.unsqueeze(0)\n",
    "            if _x is None:\n",
    "                _x = tmp\n",
    "            else:\n",
    "                _x = torch.cat((_x, tmp), dim=0)\n",
    "        \n",
    "        # (C, N, H) ===> (N, 1, C, H)   H: hidden_size\n",
    "        x = _x.permute(1, 0, 2).unsqueeze(1)\n",
    "        x = self.block_1(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return probas\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    x = torch.randn((4, 1, 64, 256)).cuda()\n",
    "    model = LSTM_CNN_Spatial(2, 4, 256, 64, 16, 16, 2).cuda()\n",
    "    #summary(model.cuda(), (4, 1, 64, 256))\n",
    "    print(model(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
